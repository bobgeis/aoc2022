==== All Days at #02917b7 ====
-- optimized release

Day 0 for in/i00.txt
  Prep:  0.20ms
  Pt 1:  0.01ms ✅ 1
  Pt 2:  0.00ms ✅ 2
  Pt 3:  0.00ms ❓ 3
  Pt4a:  0.02ms ❌ wrong -> right
  Discussion:
    d00 is a trival example. It's time represents a noisy lower bound
    for a day.
  Time:  0.38ms

Day 1 for in/i01.txt
  Prep:  0.64ms
  Pt 1:  0.00ms ✅ 68923
  Pt 2:  0.00ms ✅ 200044
  Time:  0.75ms

Day 2 for in/i02.txt
  Prep:  0.48ms
  Pt 1:  0.00ms ✅ 12276
  Pt 2:  0.00ms ✅ 9975
  Time:  0.55ms

Day 3 for in/i03.txt
  Prep:  0.46ms
  Pt 1:  0.10ms ✅ 7691
  Pt 2:  0.04ms ✅ 2508
  Time:  0.64ms

Day 4 for in/i04.txt
  Prep:  0.42ms
  Pt 1:  0.00ms ✅ 462
  Pt 2:  0.00ms ✅ 835
  Time:  0.50ms

Day 5 for in/i05.txt
  Prep:  0.43ms
  Pt 1:  0.04ms ✅ SHMSDGZVC
  Pt 2:  0.17ms ✅ VRZGHDFBQ
  Time:  0.71ms

Day 6 for in/i06.txt
  Prep:  0.19ms
  Pt 1:  0.11ms ✅ 1210
  Pt 2:  0.45ms ✅ 3476
  Time:  0.82ms

Day 7 for in/i07.txt
  Prep:  0.72ms
  Pt 1:  0.01ms ✅ 1908462
  Pt 2:  0.01ms ✅ 3979145
  Discussion:
    The input recursively walks the dirs, calling `ls` exactly once
    in each. It could have been much worse!
  Time:  0.81ms

Day 8 for in/i08.txt
  Prep:  2.77ms
  Pt 1:  0.42ms ✅ 1854
  Pt 2:  0.57ms ✅ 527340
  Discussion:
    In retrospect, part 1 and part 2 could probably have each used
    the same kind of `ray` function. But instead I did part 1 by
    walking across the whole forest from each direction and then part
    2 by walking out from each spot. There's probably improvements
    that can be done here.
  Time:  3.86ms

Day 9 for in/i09.txt
  Prep:  0.84ms
  Pt 1:  1.36ms ✅ 6243
  Pt 2:  0.57ms ✅ 2630
  Discussion:
  My first implementation had a bug where it didn't correctly account
  for intermediate knots being pulled diagonally.
  Time:  2.84ms

Day 10 for in/i10.txt
  Prep:  0.24ms
  Pt 1:  0.01ms ✅ 12980
  Pt 2:  0.01ms ✅ BRJLFULP
  Discussion:
  Aha! A day where the output is an image that you have to look at.
  Time:  0.34ms

Day 11 for in/i11.txt
  Prep:  1.07ms
  Pt 1:  0.04ms ✅ 110264
  Pt 2: 20.95ms ✅ 23612457316
  Discussion:
    My first implementation used scanTuple for parsing and it quickly
    became cumbersome. Scanf is actually much cleaner when you have
    multiple potential strings to match and it works well with
    doAssert.

    I used a trick from earlier years where you multiply all the
    period of all the loops together to get the period of a much
    larger loop. This larger period is big, but it still fits into
    an int, so we don't worry about overflow.

    Also remember that args known at compile time can be defined
    as `static` to save a little bit of work at run-time.
  Time: 22.14ms

Day 12 for in/i12.txt
  Prep:  1.02ms
  Pt 1:  3.02ms ✅ 534
  Pt 2:  2.89ms ✅ 525
  Discussion:
    A chance to use graphwalk.bfs!

    There was a bug with my initial implementation that made part 1
    take way too long.

    My first part 1 solution did bfs from start to finish, but part 2
    is easier to do via bfs from the finish towards any 'a', so
    I reversed part 1 to allow them to share code.

    There's still lots of room for improvement, but it works decently
    for now.
  Time:  6.98ms

Day 13 for in/i13.txt
  Prep:  1.58ms
  Pt 1:  0.04ms ✅ 5557
  Pt 2:  0.10ms ✅ 22425
  Pt2a:  0.50ms ✅ 22425
  Discussion:
    First thought: Can we walk the pairs of strings comparing them
    char by char?

    Second thought: Can we somehow use pegs here?

    Third thought: This is all valid json, let's just parse it!

    I hadn't used the std/json library before, so that took some
    experimentation. Once finished, it worked great and part 2 was
    very quick to code.

    For part 2 I first used the built-in sort and was well pleased
    with it, but it can be much faster. You don't actually have to
    sort the seq of JsonNodes, you just need to know how many nodes
    would be to the left of the two dividers _if_ they were sorted.
    You can do this just by looping through the array once.

    I've preserved my sorting solution as part "2a".

    It may be possible to improve parsing performance by using a
    faster json library. Several exist (eg search the nim forum).
  Time:  2.31ms

==== Total Time:  44.54ms ====
